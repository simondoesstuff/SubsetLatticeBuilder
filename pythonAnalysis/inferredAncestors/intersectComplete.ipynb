{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_nodes(path):\n",
    "    contents = open(path).read().splitlines()\n",
    "    nodes = [[int(x) for x in line.split()] for line in contents]\n",
    "    nodes = [ set(x) for x in nodes ]\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_nodes(path, results):\n",
    "    with open(path, 'w') as f:\n",
    "        for result in results:\n",
    "            f.write(' '.join([str(x) for x in result]))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Nodes 212\n",
      " - Pass 1 with 212 new nodes\n",
      " - Pass 2 with 1420 new nodes\n",
      " - Pass 3 with 8398 new nodes\n",
      " - Pass 4 with 1905 new nodes\n",
      "Time: 99.00673818588257\n",
      "Output Nodes 11935\n"
     ]
    }
   ],
   "source": [
    "# Manually finding all possible inferred ancestors\n",
    "def intersect_scan(nodes):\n",
    "    features = set(nodes)\n",
    "    frontier = set(nodes)\n",
    "    \n",
    "    passes = 0\n",
    "    \n",
    "    while len(frontier) > 0:\n",
    "        new_frontier = set()\n",
    "        new_features = set()\n",
    "        \n",
    "        passes += 1\n",
    "        print(f\" - Pass {passes} with {len(frontier)} new nodes\")\n",
    "\n",
    "        for n1 in frontier:\n",
    "            for n2 in features:\n",
    "                if len(n1) > len(n2):\n",
    "                    continue\n",
    "                \n",
    "                intersect = tuple(sorted(set(n1).intersection(set(n2))))\n",
    "                \n",
    "                if intersect not in features:\n",
    "                    if len(intersect) > 0:\n",
    "                        new_features.add(intersect)\n",
    "                        new_frontier.add(intersect)\n",
    "        \n",
    "        frontier = list(new_frontier)\n",
    "        features |= new_features\n",
    "    return features\n",
    "nodes = parse_nodes(\"../../data/dirty/1109.txt\")\n",
    "nodes = [tuple(sorted(x)) for x in nodes]\n",
    "# shuffle\n",
    "np.random.shuffle(nodes)\n",
    "nodes = nodes[:212]\n",
    "\n",
    "print(f\"Input Nodes\", len(nodes))\n",
    "\n",
    "t0 = time.time()\n",
    "scan = intersect_scan(nodes)\n",
    "t1 = time.time()\n",
    "\n",
    "print(f\"Time: {t1-t0}\")\n",
    "print('Output Nodes', len(scan))\n",
    "\n",
    "\n",
    "# Write results to file\n",
    "results = list(scan)\n",
    "write_nodes(\"../../data/int_complete/13516_out.nodes\", results)\n",
    "\n",
    "# Write input nodes to file\n",
    "write_nodes(\"../../data/int_complete/setA/212_in.nodes\", nodes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
