{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from libs.nodes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersect Complete\n",
    "\n",
    "Data generated from a given set of \"observed\" nodes by taking the intersections off all the nodes among each other. This process is repeated\n",
    "(including with the new data) until no further intersections can be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Nodes 212\n",
      " - Pass 1 with 212 new nodes\n",
      " - Pass 2 with 2095 new nodes\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput Nodes\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlen\u001b[39m(nodes))\n\u001b[1;32m     36\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 37\u001b[0m scan \u001b[39m=\u001b[39m intersect_scan(nodes)\n\u001b[1;32m     38\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     40\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTime: \u001b[39m\u001b[39m{\u001b[39;00mt1\u001b[39m-\u001b[39mt0\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m, in \u001b[0;36mintersect_scan\u001b[0;34m(nodes)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(n1) \u001b[39m>\u001b[39m \u001b[39mlen\u001b[39m(n2):\n\u001b[1;32m     18\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m intersect \u001b[39m=\u001b[39m n1 \u001b[39m&\u001b[39;49m n2\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m intersect \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m features:\n\u001b[1;32m     23\u001b[0m     \u001b[39mif\u001b[39;00m intersect:\n",
      "File \u001b[0;32m~/Code/work/SubsetLatticeBuilder/pythonAnalysis/inferredAncestors/libs/nodes.py:29\u001b[0m, in \u001b[0;36mnode.__and__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__and__\u001b[39m(\u001b[39mself\u001b[39m, other: AbstractSet) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Self:\n\u001b[0;32m---> 29\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintersection(other)\n",
      "File \u001b[0;32m~/Code/work/SubsetLatticeBuilder/pythonAnalysis/inferredAncestors/libs/nodes.py:20\u001b[0m, in \u001b[0;36mnode.intersection\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mintersection\u001b[39m(\u001b[39mself\u001b[39m, other: Iterable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Self:\n\u001b[0;32m---> 20\u001b[0m     \u001b[39mreturn\u001b[39;00m node(\u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mintersection(other))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Manually finding all possible inferred ancestors\n",
    "def intersect_scan(nodes):\n",
    "    features = set(nodes)\n",
    "    frontier = set(nodes)\n",
    "    \n",
    "    passes = 0\n",
    "    \n",
    "    while len(frontier) > 0:\n",
    "        new_frontier = set()\n",
    "        new_features = set()\n",
    "        \n",
    "        passes += 1\n",
    "        print(f\" - Pass {passes} with {len(frontier)} new nodes\")\n",
    "\n",
    "        for n1 in frontier:\n",
    "            for n2 in features:\n",
    "                if len(n1) > len(n2):\n",
    "                    continue\n",
    "                \n",
    "                intersect = n1 & n2\n",
    "                \n",
    "                if intersect not in features:\n",
    "                    if intersect:\n",
    "                        new_features.add(intersect)\n",
    "                        new_frontier.add(intersect)\n",
    "        \n",
    "        frontier = list(new_frontier)\n",
    "        features |= new_features\n",
    "    return features\n",
    "nodes = parse_nodes(\"../../data/dirty/1109.txt\")\n",
    "np.random.shuffle(nodes)\n",
    "nodes = nodes[:212]\n",
    "\n",
    "print(f\"Input Nodes\", len(nodes))\n",
    "\n",
    "t0 = time.time()\n",
    "scan = intersect_scan(nodes)\n",
    "t1 = time.time()\n",
    "\n",
    "print(f\"Time: {t1-t0}\")\n",
    "print('Output Nodes', len(scan))\n",
    "\n",
    "\n",
    "# Write results to file\n",
    "results = list(scan)\n",
    "write_nodes(\"../../data/int_complete/13516_out.nodes\", results)\n",
    "\n",
    "# Write input nodes to file\n",
    "write_nodes(\"../../data/int_complete/setA/212_in.nodes\", nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjacent Intersections\n",
    "\n",
    "Referring to intersections of given, observed nodes and other inferred nodes, but with the constraint that all inferred nodes share at least\n",
    "one leg with an observed node. That is, intersections are generated either by observed <-> observed or observed <-> inferred, but never\n",
    "inferred <-> inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_adj(nodes: list[node]):\n",
    "    total = set()\n",
    "    frontier = set()\n",
    "    \n",
    "    frontier.update(nodes) # Start with all nodes\n",
    "    \n",
    "    while len(frontier) > 0:\n",
    "        new_frontier = set()\n",
    "        \n",
    "        for n1 in nodes:\n",
    "            for n2 in frontier:\n",
    "                # n1 > n2 condition prevents duplicate comparisons\n",
    "                if n1 == n2 or len(n1) > len(n2):\n",
    "                    continue\n",
    "                \n",
    "                intersect = n1 & n2\n",
    "                \n",
    "                if intersect and intersect not in total:\n",
    "                    new_frontier.add(intersect)\n",
    "        \n",
    "        total.update(frontier)\n",
    "        frontier = new_frontier\n",
    "        print(f\"- {len(frontier)} new --> {len(total)} accumulated\")\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 2 new --> 3 accumulated\n",
      "- 0 new --> 5 accumulated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(1,2), (1,2,3,4), (1,2,3,5), (1,2,6,7), (1,2,3)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = [\n",
    "    node('1234'),\n",
    "    node('1235'),\n",
    "    node('1267'),\n",
    "]\n",
    "\n",
    "int_adj(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test is successful. $(1,2,3)$ is an observed <-> observed inference. But, $(1, 2)$ is an observed <-> inferred inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 6899 new --> 1109 accumulated\n",
      "- 15845 new --> 7074 accumulated\n",
      "- 11709 new --> 16954 accumulated\n",
      "- 1883 new --> 18783 accumulated\n",
      "- 54 new --> 18837 accumulated\n",
      "- 0 new --> 18837 accumulated\n"
     ]
    }
   ],
   "source": [
    "nodes = parse_nodes(\"../../data/dirty/1109.txt\")\n",
    "np.random.shuffle(nodes)\n",
    "nodes_in = nodes[:500]\n",
    "nodes_out = int_adj(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_nodes(\"../../data/int_adj/setA/500_in.nodes\", nodes_in)\n",
    "write_nodes(\"../../data/int_adj/setA/18837_out.nodes\", nodes_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
